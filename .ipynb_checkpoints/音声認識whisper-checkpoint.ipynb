{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137e0a06",
   "metadata": {},
   "source": [
    "# 各種パラメーター設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "12167fbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T10:16:20.380131Z",
     "start_time": "2022-11-17T10:16:20.368171Z"
    }
   },
   "outputs": [],
   "source": [
    "target_id = \"id1_1\"\n",
    "rawdata_folder_path = \"/Users/k-shintomi/Documents/幼保/LITALICO/rawdata/\"\n",
    "analysis_folder_path = \"/Users/k-shintomi/Documents/幼保/LITALICO/analysis/\"\n",
    "rawdata_path = rawdata_folder_path+target_id+\".mp3\"\n",
    "trimming_path =rawdata_folder_path+target_id+\"_trimming.wav\"\n",
    "#save_text_path = analysis_folder_path+target_id+\"_音声認識_whisper_with_vad.txt\"\n",
    "#save_json_path = analysis_folder_path+target_id+\"_音声認識_whisper_with_vad.json\"\n",
    "save_srt_path = analysis_folder_path+target_id+\"_音声認識_whisper_with_vad.srt\"\n",
    "#人の声が入っているかどうかを識別するパラメーター。　オーディオチャンク毎に確率が出る。デフォルトは0.5\n",
    "vad_threshold=0.3\n",
    "# 音声ファイルを分割するための閾値。大きくすればするほど、一つのファイルに複数の音声が入る。\n",
    "#whisperの処理性能的にある程度長めの音声で判定しているので、一つのファイルに複数の音声を詰め込むと処理性能が落ちる？\n",
    "#要実験\n",
    "chunk_threshold = 1\n",
    "#音声に対する感度を少し下げる（このワードを検知したら無視する可能性が高い）\n",
    "suppress_low = [\n",
    "    \"視聴\",\n",
    "    \"視聴\",\n",
    "]\n",
    "#音声に対する感度を大きく下げる\n",
    "suppress_high = [\n",
    "    \"ご視聴\",\n",
    "    \"視聴ありがとうございました\",\n",
    "    \"ご視聴ありがとうございました!\"\n",
    "    \"私はあなたを愛しています。\"\n",
    "]\n",
    "#音声に対する感度を大きく上げる\n",
    "promotion_high = [\n",
    "    \"座る\",\n",
    "]\n",
    "#whisperの試行回数\n",
    "max_attempts=1\n",
    "#whisperモデルで無音判定する閾値。高いほど1.0に近づくほど無音の可能性が高い。デフォルトは0.6\n",
    "no_speech_threshold= 0.7\n",
    "#whisperモデルで喋り声の判定する閾値。高いほど喋っている可能性が高い。デフォルト-1.0\n",
    "avg_logprob = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55bf4b",
   "metadata": {},
   "source": [
    "# モデルのインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c68bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T07:22:38.823594Z",
     "start_time": "2022-11-16T07:22:37.327613Z"
    }
   },
   "source": [
    "!pip install pydub\n",
    "!pip install torchaudio\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f8cac919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:41:47.365247Z",
     "start_time": "2022-11-17T07:41:47.347962Z"
    }
   },
   "outputs": [],
   "source": [
    "from srt import Subtitle\n",
    "from pydub import AudioSegment\n",
    "import srt\n",
    "import torch\n",
    "import whisper\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71763b6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:21:19.824415Z",
     "start_time": "2022-11-17T05:21:07.346352Z"
    }
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "799f53ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:22:41.778058Z",
     "start_time": "2022-11-17T05:22:37.290672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025789976119995117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 36,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1920044,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1879713b2f64909be9eaf9e9efda532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /Users/k-shintomi/.cache/torch/hub/master.zip\n"
     ]
    }
   ],
   "source": [
    "# vad(voice acitivity detectorモデルのインストール)\n",
    "SAMPLING_RATE = 16000\n",
    "torch.set_num_threads(1)\n",
    "torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\n",
    "\n",
    "USE_ONNX = False # change this to True if you want to test onnx model\n",
    "if USE_ONNX:\n",
    "    !pip install -q onnxruntime\n",
    "model_vad, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=USE_ONNX)\n",
    "\n",
    "#utlisの各種メソッドが代入される\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612de1e7",
   "metadata": {},
   "source": [
    "# 音声ファイルの読み込み・作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e27a5fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:27:51.501301Z",
     "start_time": "2022-11-17T05:27:45.869873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/k-shintomi/Documents/幼保/LITALICO/rawdata/id1_1_trimming.wav'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#音声ファイルの読み込み\n",
    "sound = AudioSegment.from_file(rawdata_path, format=\"mp3\")\n",
    "#単位はms秒\n",
    "sound1 = sound[:60*1000*3]\n",
    "sound1.export(trimming_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237b1c2",
   "metadata": {},
   "source": [
    "# vadによる話し声の有無判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "453d3e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T06:21:09.934505Z",
     "start_time": "2022-11-17T06:21:04.267138Z"
    }
   },
   "outputs": [],
   "source": [
    "#タイムスタンプの作成\n",
    "sound_val = read_audio(trimming_path, sampling_rate=SAMPLING_RATE)\n",
    "speech_timestamps = get_speech_timestamps(sound_val, model_vad, sampling_rate=SAMPLING_RATE, threshold=vad_threshold)\n",
    "#pprint(speech_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e015320b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T06:28:19.416228Z",
     "start_time": "2022-11-17T06:28:19.408542Z"
    }
   },
   "outputs": [],
   "source": [
    "# 声の間がchunk_thresholdよりも長かったら音声ファイルを複数に分割する様にする。\n",
    "u = [[]]\n",
    "for i in range(len(speech_timestamps)):\n",
    "    if i > 0 and speech_timestamps[i][\"start\"] > speech_timestamps[i - 1][\"end\"] + (chunk_threshold * SAMPLING_RATE):\n",
    "        u.append([])\n",
    "    u[-1].append(speech_timestamps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d42042f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T06:28:19.985558Z",
     "start_time": "2022-11-17T06:28:19.944883Z"
    }
   },
   "outputs": [],
   "source": [
    "# 人の声が入っている部分だけを抽出。\n",
    "#処理時間を短縮することができる\n",
    "for i in range(len(u)):\n",
    "    save_audio(\"vad_chunks_\" + str(i) + \".wav\",\n",
    "               collect_chunks(u[i], sound_val),\n",
    "               sampling_rate=SAMPLING_RATE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14b19002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:12:55.870164Z",
     "start_time": "2022-11-17T07:12:55.860113Z"
    }
   },
   "outputs": [],
   "source": [
    "# タイムスタンプを秒に変換\n",
    "for i in range(len(u)):\n",
    "    time = 0.0\n",
    "    offset = 0.0\n",
    "    for j in range(len(u[i])):\n",
    "        u[i][j][\"start\"] /= SAMPLING_RATE\n",
    "        u[i][j][\"end\"] /= SAMPLING_RATE\n",
    "        u[i][j][\"chunk_start\"] = time\n",
    "        time += u[i][j][\"end\"] - u[i][j][\"start\"]\n",
    "        u[i][j][\"chunk_end\"] = time\n",
    "        if j == 0:\n",
    "            offset += u[i][j][\"start\"]\n",
    "        else:\n",
    "            offset += u[i][j][\"start\"] - u[i][j - 1][\"end\"]\n",
    "        u[i][j][\"offset\"] = offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27739e5",
   "metadata": {},
   "source": [
    "# whisperによる音声解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f48b9f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:28:35.793119Z",
     "start_time": "2022-11-17T05:28:23.795424Z"
    }
   },
   "outputs": [],
   "source": [
    "mode_whisperl = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22f2bf13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:19:08.170098Z",
     "start_time": "2022-11-17T07:19:08.166317Z"
    }
   },
   "outputs": [],
   "source": [
    "subs = []\n",
    "segment_info = []\n",
    "sub_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3bec397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:11:33.357470Z",
     "start_time": "2022-11-17T07:50:55.789588Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                               | 0/16 [00:00<?, ?it/s]/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "  6%|██████▍                                                                                                | 1/16 [00:15<03:54, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] ご視聴ありがとうございました!\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 12%|████████████▉                                                                                          | 2/16 [00:32<03:51, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] ご視聴ありがとうございました!\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 19%|███████████████████▎                                                                                   | 3/16 [01:03<04:58, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] ご視聴ありがとうございました!\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] キーワードを\n",
      "[00:02.000 --> 00:03.000] キーワード\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████████████████▊                                                                             | 4/16 [01:41<05:47, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03.000 --> 00:30.000] キーワード\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 31%|████████████████████████████████▏                                                                      | 5/16 [01:57<04:26, 24.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] ご視聴ありがとうございました!\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 38%|██████████████████████████████████████▎                                                               | 6/16 [07:38<21:58, 131.86s/it]/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 44%|█████████████████████████████████████████████                                                          | 7/16 [07:53<14:03, 93.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] えきえきえき\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 50%|███████████████████████████████████████████████████                                                   | 8/16 [13:41<23:18, 174.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.220] トラック中\n",
      "[00:10.180 --> 00:07.820] 3 新出版\n",
      "[00:08.300 --> 00:11.760] エイパー slept\n",
      "[00:14.400 --> 00:17.200] おт\n",
      "[00:21.260 --> 00:20.660] 2\n",
      "[00:21.280 --> 00:23.440] エイアー\n",
      "[00:24.900 --> 00:26.340] 3\n",
      "[00:27.460 --> 00:29.540]  ultimately\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 56%|█████████████████████████████████████████████████████████▍                                            | 9/16 [14:04<14:50, 127.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:03.000] 落ちてくわしゃい。バカと落ちてね。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:06.000] またねー ありがとうねー\n",
      "[00:06.000 --> 00:08.760] 撮らせてくれて\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████████████████████▏                                     | 10/16 [14:46<10:05, 100.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:08.760 --> 00:33.760] 集中してます\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 69%|██████████████████████████████████████████████████████████████████████▏                               | 11/16 [15:03<06:15, 75.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] アイスクリーム\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      " 75%|████████████████████████████████████████████████████████████████████████████▌                         | 12/16 [15:20<03:50, 57.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] ご視聴ありがとうございました!\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] 私見て大丈夫そうだから\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████████████████████▉                   | 13/16 [15:54<02:31, 50.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02.000 --> 00:04.000] はい\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] リップ、何をのボールが遊んでるの?\n",
      "[00:02.000 --> 00:04.000] 大変じゃん!\n",
      "[00:04.000 --> 00:06.000] 大変じゃん!\n",
      "[00:06.000 --> 00:08.000] 大変じゃん!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████▎            | 14/16 [16:48<01:42, 51.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:08.000 --> 00:34.000] 大変じゃん!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:02.000] ねえ\n",
      "[00:02.000 --> 00:04.000] トントンしてよ\n",
      "[00:04.000 --> 00:06.000] 赤いボール\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████▋      | 15/16 [17:33<00:49, 49.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:06.000 --> 00:31.000] トントンしてください\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-shintomi/Downloads/yes/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.300 --> 00:03.300] 啞 qui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [20:37<00:00, 77.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03.300 --> 00:05.300] パンパンしてください\n",
      "do_skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(u))):\n",
    "    line_buffer = []  # Used for DeepL\n",
    "    for x in range(max_attempts):\n",
    "        result = model.transcribe(\n",
    "            \"vad_chunks_\" + str(i) + \".wav\", \n",
    "            verbose=False, language=\"ja\",\n",
    "            no_speech_threshold=no_speech_threshold,\n",
    "        logprob_threshold=avg_logprob)\n",
    "        # Break if result doesn't end with severe hallucinations\n",
    "        if len(result[\"segments\"]) == 0:\n",
    "            break\n",
    "        elif result[\"segments\"][-1][\"end\"] < u[i][-1][\"chunk_end\"] + 10.0:\n",
    "            break\n",
    "        elif x+1 < max_attempts:\n",
    "            print(\"Retrying chunk\", i)\n",
    "    for r in result[\"segments\"]:\n",
    "        # Skip audio timestamped after the chunk has ended\n",
    "        if r[\"start\"] > u[i][-1][\"chunk_end\"]:\n",
    "            continue\n",
    "        # 特定のワード、フレーズに対して感度を調整\n",
    "        for s in suppress_low:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.30\n",
    "        for s in suppress_high:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.50\n",
    "        for s in promotion_high:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] += 0.20\n",
    "        if r[\"avg_logprob\"] < avg_logprob or r[\"no_speech_prob\"] > no_speech_threshold:\n",
    "            #print(\"do_skip\")\n",
    "            continue\n",
    "        # セグメント情報を保持\n",
    "        del r[\"tokens\"]\n",
    "        segment_info.append(r)\n",
    "        # Set start timestamp\n",
    "        start = r[\"start\"] + u[i][0][\"offset\"]\n",
    "        for j in range(len(u[i])):\n",
    "            if (\n",
    "                r[\"start\"] >= u[i][j][\"chunk_start\"]\n",
    "                and r[\"start\"] <= u[i][j][\"chunk_end\"]\n",
    "            ):\n",
    "                start = r[\"start\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # subsの重複を避ける\n",
    "        if len(subs) > 0:\n",
    "            last_end = datetime.timedelta.total_seconds(subs[-1].end)\n",
    "            if last_end > start:\n",
    "                subs[-1].end = datetime.timedelta(seconds=start)\n",
    "        # タイムスタンプの終わりを判定\n",
    "        end = u[i][-1][\"end\"] + 0.5\n",
    "        for j in range(len(u[i])):\n",
    "            if r[\"end\"] >= u[i][j][\"chunk_start\"] and r[\"end\"] <= u[i][j][\"chunk_end\"]:\n",
    "                end = r[\"end\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # Add to SRT list\n",
    "        subs.append(\n",
    "            srt.Subtitle(\n",
    "                index=sub_index,\n",
    "                start=datetime.timedelta(seconds=start),\n",
    "                end=datetime.timedelta(seconds=end),\n",
    "                content=r[\"text\"].strip(),\n",
    "            )\n",
    "        )\n",
    "        sub_index += 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da6032",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-17T04:00:17.566Z"
    }
   },
   "outputs": [],
   "source": [
    "#srtファイルの作成\n",
    "with open(\"/Users/k-shintomi/Documents/幼保/LITALICO/analysis/id1_1_音声認識_whisper_metadata.json\", \"w\") as f:\n",
    "    json.dump(result[\"segments\"], f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
